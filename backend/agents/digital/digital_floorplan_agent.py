import os
import json
import glob
import shutil
import subprocess
from datetime import datetime

from utils.artifact_utils import save_text_artifact_and_record

AGENT_NAME = "Digital Floorplan Agent"

DEFAULT_PDK_VARIANT = os.getenv("CHIPLOOP_PDK_VARIANT", "sky130A")
DEFAULT_OPENLANE_IMAGE = os.getenv("CHIPLOOP_OPENLANE_IMAGE", "ghcr.io/efabless/openlane2:2.4.0.dev1")
DEFAULT_NUM_CORES = int(os.getenv("OPENLANE_NUM_CORES", "2"))


def _ensure_dir(p: str) -> None:
    os.makedirs(p, exist_ok=True)


def _read_json(path: str) -> dict:
    try:
        with open(path, "r", encoding="utf-8") as f:
            return json.load(f)
    except Exception:
        return {}


def _write_text(path: str, content: str) -> None:
    _ensure_dir(os.path.dirname(path))
    with open(path, "w", encoding="utf-8") as f:
        f.write(content)


def _run(cmd: list[str], cwd: str) -> tuple[int, str]:
    p = subprocess.Popen(cmd, cwd=cwd, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)
    out, _ = p.communicate()
    return p.returncode, out


def _latest_run_dir(stage_dir: str) -> str | None:
    runs_dir = os.path.join(stage_dir, "runs")
    if not os.path.isdir(runs_dir):
        return None
    dirs = [os.path.join(runs_dir, d) for d in os.listdir(runs_dir) if os.path.isdir(os.path.join(runs_dir, d))]
    if not dirs:
        return None
    dirs.sort(key=lambda p: os.path.getmtime(p))
    return dirs[-1]


def _copy_metrics(latest: str | None, stage_dir: str) -> str | None:
    if not latest:
        return None
    src = os.path.join(latest, "final", "metrics.json")
    dst = os.path.join(stage_dir, "metrics.json")
    if os.path.exists(src):
        shutil.copy2(src, dst)
        return dst
    return None


def _copy_primary_def(latest: str | None, stage_dir: str) -> str | None:
    if not latest:
        return None
    dst = os.path.join(stage_dir, "primary.def")
    candidates = []
    candidates += glob.glob(os.path.join(latest, "final", "def", "*.def"))
    candidates += glob.glob(os.path.join(latest, "results", "**", "*.def"), recursive=True)
    if not candidates:
        return None
    candidates.sort(key=lambda p: os.path.getsize(p))
    shutil.copy2(candidates[-1], dst)
    return dst


def run_agent(state: dict) -> dict:
    print(f"\nüèÅ Running {AGENT_NAME}...")

    workflow_id = state.get("workflow_id", "default")
    workflow_dir = state.get("workflow_dir") or f"backend/workflows/{workflow_id}"

    stage_dir = os.path.join(workflow_dir, "digital", "floorplan")
    logs_dir = os.path.join(stage_dir, "logs")
    constraints_dir = os.path.join(stage_dir, "constraints")

    _ensure_dir(stage_dir)
    _ensure_dir(logs_dir)
    _ensure_dir(constraints_dir)

    # Single source-of-truth SDC from Arch2RTL
    upstream_sdc = os.path.join(workflow_dir, "digital", "constraints", "top.sdc")
    if not os.path.exists(upstream_sdc):
        raise RuntimeError("Missing upstream SDC: digital/constraints/top.sdc (must be generated by Arch2RTL).")
    stage_sdc = os.path.join(constraints_dir, "top.sdc")
    shutil.copy2(upstream_sdc, stage_sdc)
    with open(stage_sdc, "r", encoding="utf-8") as f:
        sdc_text = f.read()

    # Use Implementation Setup config if present; else synth config
    impl_cfg = os.path.join(workflow_dir, "digital", "foundry", "openlane", "config.json")
    synth_cfg = os.path.join(workflow_dir, "digital", "synth", "config.json")
    base_cfg_path = impl_cfg if os.path.exists(impl_cfg) else synth_cfg
    if not os.path.exists(base_cfg_path):
        raise RuntimeError("Missing OpenLane config. Expected digital/foundry/openlane/config.json or digital/synth/config.json")

    cfg = _read_json(base_cfg_path)
    # Force SDC reference to stage-local copy
    cfg["SYNTH_SDC_FILE"] = "constraints/top.sdc"
    cfg["PNR_SDC_FILE"] = "constraints/top.sdc"

    config_path = os.path.join(stage_dir, "config.json")
    _write_text(config_path, json.dumps(cfg, indent=2))

    # ---- Docker/run.sh ----
    pdk_variant = state.get("pdk_variant") or DEFAULT_PDK_VARIANT
    openlane_image = state.get("openlane_image") or DEFAULT_OPENLANE_IMAGE
    pdk_root_host = os.getenv("CHIPLOOP_PDK_ROOT_HOST") or "/root/chiploop-backend/backend/pdk"
    run_tag = f"floorplan_{workflow_id}"

    run_sh = f"""#!/usr/bin/env bash
set -euo pipefail

echo "== ChipLoop: {AGENT_NAME} =="
echo "PDK_VARIANT={pdk_variant}"
echo "OPENLANE_IMAGE={openlane_image}"
echo "WORKDIR=/work"

export OPENLANE_NUM_CORES={DEFAULT_NUM_CORES}

docker run --rm \\
  -v "{pdk_root_host}":/pdk \\
  -v "$(pwd)":/work \\
  -e PDK={pdk_variant} \\
  -e PDK_ROOT=/pdk \\
  {openlane_image} \\
  bash -lc 'set -e; echo "PDK listing:"; ls -la /pdk | head -n 50; cd /work && openlane --flow Classic --run-tag {run_tag} --to OpenROAD.Floorplan config.json'
"""
    run_sh_path = os.path.join(stage_dir, "run.sh")
    _write_text(run_sh_path, run_sh)
    os.chmod(run_sh_path, 0o755)

    rc, out = _run(["bash", "-lc", "./run.sh"], cwd=stage_dir)
    log_path = os.path.join(logs_dir, "openlane_floorplan.log")
    _write_text(log_path, out)

    latest = _latest_run_dir(stage_dir)
    metrics_path = _copy_metrics(latest, stage_dir)
    def_path = _copy_primary_def(latest, stage_dir)

    summary = {
        "workflow_id": workflow_id,
        "agent": AGENT_NAME,
        "status": "ok" if rc == 0 else "failed",
        "return_code": rc,
        "outputs": {
            "sdc": "digital/floorplan/constraints/top.sdc",
            "metrics_json": "digital/floorplan/metrics.json" if metrics_path else None,
            "primary_def": "digital/floorplan/primary.def" if def_path else None,
            "log": "digital/floorplan/logs/openlane_floorplan.log",
            "openlane_run_dir": latest,
        },
    }

    _write_text(os.path.join(stage_dir, "floorplan_summary.json"), json.dumps(summary, indent=2))
    _write_text(os.path.join(stage_dir, "floorplan_summary.md"), f"# Floorplan\n\n- status: `{summary['status']}` (rc={rc})\n")

    # ---- Upload text artifacts (DEF is text; ok to upload for small designs) ----
    try:
        save_text_artifact_and_record(workflow_id, AGENT_NAME, "digital", "floorplan/config.json", json.dumps(cfg, indent=2))
        save_text_artifact_and_record(workflow_id, AGENT_NAME, "digital", "floorplan/constraints/top.sdc", sdc_text)
        save_text_artifact_and_record(workflow_id, AGENT_NAME, "digital", "floorplan/run.sh", run_sh)
        save_text_artifact_and_record(workflow_id, AGENT_NAME, "digital", "floorplan/logs/openlane_floorplan.log", out)
        save_text_artifact_and_record(workflow_id, AGENT_NAME, "digital", "floorplan/floorplan_summary.json", json.dumps(summary, indent=2))
        if metrics_path and os.path.exists(metrics_path):
            with open(metrics_path, "r", encoding="utf-8") as f:
                save_text_artifact_and_record(workflow_id, AGENT_NAME, "digital", "floorplan/metrics.json", f.read())
        if def_path and os.path.exists(def_path):
            with open(def_path, "r", encoding="utf-8", errors="ignore") as f:
                save_text_artifact_and_record(workflow_id, AGENT_NAME, "digital", "floorplan/primary.def", f.read())
    except Exception as e:
        print(f"‚ö†Ô∏è {AGENT_NAME} upload failed: {e}")

    state.setdefault("digital", {})["floorplan"] = {
        "status": summary["status"],
        "stage_dir": stage_dir,
        "metrics_json": metrics_path,
        "primary_def": def_path,
    }
    return state
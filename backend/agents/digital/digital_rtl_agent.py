import os
import re
import json
import datetime
import subprocess
import requests
from portkey_ai import Portkey
from openai import OpenAI
from utils.artifact_utils import save_text_artifact_and_record

OLLAMA_URL = "http://127.0.0.1:11434/api/generate"
USE_LOCAL_OLLAMA = os.getenv("USE_LOCAL_OLLAMA", "false").lower() == "true"
PORTKEY_API_KEY = os.getenv("PORTKEY_API_KEY")
client_portkey = Portkey(
    api_key=PORTKEY_API_KEY
)
client_openai = OpenAI()

def run_agent(state: dict) -> dict:

    agent_name = "Digital RTL Agent"
    print("\nüß† Running RTL Agent (Spec-Aware Validation)...")

    # --- Added: Multi-user workflow isolation ---
    workflow_id = state.get("workflow_id", "default")
    workflow_dir = state.get("workflow_dir", f"backend/workflows/{workflow_id}")
    os.makedirs(workflow_dir, exist_ok=True)
    # --------------------------------------------
    artifact_list = state.get("artifact_list", [])
    if artifact_list:
        print(f"üß© Hierarchical design detected with {len(artifact_list)} modules.")
        merged_path = os.path.join(workflow_dir, "hierarchy_compile.v")
        with open(merged_path, "w") as merged:
            for fpath in artifact_list:
                if not os.path.exists(fpath):
                    print(f"‚ö†Ô∏è Missing module file: {fpath}")
                    continue
                with open(fpath, "r") as src:
                    merged.write(f"// === {os.path.basename(fpath)} ===\n")
                    merged.write(src.read() + "\n\n")
        rtl_file = merged_path
    else:
        rtl_file = state.get("artifact")
        if not rtl_file or not os.path.exists(rtl_file):
            v_files = [f for f in os.listdir(workflow_dir) if f.endswith(".v")]
            if not v_files:
                raise FileNotFoundError(f"No RTL (.v) file found in {workflow_dir}")
            rtl_file = os.path.join(workflow_dir, v_files[0])


    print(f"‚úÖ Using RTL file: {rtl_file}")
    # Detect the JSON spec file dynamically
    spec_file = state.get("spec_json")
    if not spec_file or not os.path.exists(spec_file):
        json_candidates = [f for f in os.listdir(workflow_dir) if f.endswith("_spec.json")]
        if not json_candidates:
          raise FileNotFoundError(f"No spec JSON file found in {workflow_dir}")
        spec_file = os.path.join(workflow_dir, json_candidates[0])
        

    if not os.path.exists(rtl_file):
        state["status"] = f"‚ùå RTL file '{rtl_file}' not found."
        return state
    if not spec_file or not os.path.exists(spec_file):
        state["status"] = "‚ö† Spec JSON not found ‚Äî limited validation mode."
        spec = {}
    else:
        with open(spec_file, "r") as f:
            spec = json.load(f)

    # --- Step 1: Basic Verilog Syntax Lint via Icarus ---
    log_path = os.path.join(workflow_dir, "rtl_agent_compile.log")
    try:
        # üîß Hierarchical compilation: include all modules
        v_files = [os.path.join(workflow_dir, f) for f in os.listdir(workflow_dir) if f.endswith(".v")]
        compile_cmd = ["/usr/bin/iverilog", "-o", "rtl_check.out"] + v_files
        print(f"üß© Running hierarchical compile on {len(v_files)} RTL files: {[os.path.basename(f) for f in v_files]}")

        result = subprocess.run(
           compile_cmd,
           check=True,
           capture_output=True,
           text=True
        )

        compile_status = "‚úÖ Verilog syntax check passed."
    except subprocess.CalledProcessError as e:
        compile_status = "‚ö† Verilog syntax check failed."
        error_log = (e.stderr or e.stdout or "").strip()
        with open(log_path, "w") as logf:
            logf.write(error_log)
        state.update({
            "status": compile_status,
            "error_log": error_log,
            "artifact_log": log_path,
            "workflow_id": workflow_id,
            "workflow_dir": workflow_dir
        })
        return state

    # --- Step 2: Extract RTL ports from Verilog ---
    with open(rtl_file, "r") as f:
        verilog_text = f.read()


    ports = re.findall(r"(?:input|output|inout)\s+(?:wire|reg|logic)?\s*(?:\[[^\]]+\]\s*)?(\w+)", verilog_text)
    port_names = ports

    print(f"üîç Extracted ports: {port_names}")

    clocks_detected = [p for p in port_names if re.search(r"clk|clock", p, re.IGNORECASE)]
    resets_detected = [p for p in port_names if re.search(r"rst|reset", p, re.IGNORECASE)]

    if "io" not in spec and "ports" in spec and isinstance(spec["ports"], list):
        ins = []
        outs = []
        for p in spec["ports"]:
            try:
                nm = p.get("name")
                if not nm: continue
                if p.get("direction") == "input":
                    width = int(p.get("width", 1))
                    ins.append(nm if width == 1 else f"{nm}[{width-1}:0]")
                elif p.get("direction") == "output":
                    width = int(p.get("width", 1))
                    outs.append(nm if width == 1 else f"{nm}[{width-1}:0]")
            except Exception:
                continue
        spec["io"] = {"inputs": ins, "outputs": outs}

    # --- Step 3: Validate with spec.json ---
    issues = []
    if "clock" in spec:
        for clk in spec["clock"]:
            name = clk["name"]
            if name not in port_names:
                issues.append(f"‚ùå Clock '{name}' missing in RTL ports.")
    if "reset" in spec:
        for rst in spec["reset"]:
            name = rst["name"]
            if name not in port_names:
                issues.append(f"‚ùå Reset '{name}' missing in RTL ports.")
    if "io" in spec:
        for pin in spec["io"].get("inputs", []):
            pin_name = re.split(r"\[", pin)[0]
            if pin_name not in port_names:
                issues.append(f"‚ö† Input '{pin}' not found in RTL.")
        for pin in spec["io"].get("outputs", []):
            pin_name = re.split(r"\[", pin)[0]
            if pin_name not in port_names:
                issues.append(f"‚ö† Output '{pin}' not found in RTL.")

    # --- Step 4: Optional LLM-based linting ---
    lint_feedback = ""
    try:
        lint_prompt = f"""
You are a senior RTL reviewer.
Analyze the following Verilog hierarchy for logic or style issues.
If multiple modules are present, ensure consistent signal naming,
no duplicate clk/reset declarations, and correct submodule instantiations.
Summarize key issues clearly.
Make sure below rules are followed
Generate synthesizable Verilog-2005 code for this specification.
Output must start with 'module' and end with 'endmodule'.
Do NOT include markdown code fences or explanations.
Ensure all ports are declared inside parentheses in the module declaration. 
Avoid duplicate declarations of signals like clk, reset, or common ports.
Each signal is declared only once across all modules.
Do not repeat `clk`, `reset`, or any input/output in submodules if already declared in the top module.
Avoid declaring loop indices (like i) globally.
Generate clean synthesizable Verilog with consistent indentation
Do NOT include undefined macros like `sv`, `enable`, or custom defines.
End every statement with a semicolon and close with `endmodule` only once.
Provide only compilable Verilog/SystemVerilog code ‚Äî no explanations or comments outside the code.
Include all input/output declarations explicitly
- Use lowercase signal names.
- Declare all ports explicitly.
- For multiple clocks, create independent always blocks.
- For control or arithmetic designs, infer appropriate logic cleanly.
{verilog_text[:3000]}
"""
        if USE_LOCAL_OLLAMA:
            payload = {"model": "llama3", "prompt": lint_prompt}
            r = requests.post(OLLAMA_URL, json=payload, timeout=60)
            lint_feedback = r.text.strip()
        else:
            response = client_portkey.chat.completions.create(
                model="@chiploop/gpt-4o-mini",
                messages=[{"role": "user", "content": lint_prompt}],
            )
            lint_feedback = response.choices[0].message.get("content", "")  
    except Exception as e:
        lint_feedback = f"(Skipped LLM lint due to {e})"

    # --- Step 5: Log Summary ---
    with open(log_path, "w") as logf:
        logf.write(f"RTL Validation Log ‚Äî {datetime.datetime.now()}\n\n")
        logf.write(f"{compile_status}\n\n")
        if issues:
            logf.write("Spec mismatches:\n")
            logf.writelines(f"- {i}\n" for i in issues)
        else:
            logf.write("‚úÖ All spec ports found in RTL.\n")
        logf.write("\nüîç LLM Review Summary:\n")
        logf.write(lint_feedback)

    # --- Step 6: Update state ---
    overall_status = "‚ö† RTL validation completed with mismatches." if issues else "‚úÖ RTL validated successfully."

    state.update({
        "status": overall_status,
        "artifact_log": log_path,
        "lint_feedback": lint_feedback,
        "port_list": port_names,
        "clock_ports": clocks_detected,
        "reset_ports": resets_detected,
        "issues": issues,
        "workflow_id": workflow_id,
        "workflow_dir": workflow_dir
    })
    # --- üì¶ Upload artifacts to Supabase Storage ---

        # --- üì¶ Upload artifacts to Supabase Storage ---
    try:
        user_id = state.get("user_id", "anonymous")  # kept if you still need it later
        workflow_id = state.get("workflow_id", "default")


        # 1) RTL compile log
        try:
            with open(log_path, "r") as lf:
                log_content = lf.read()
            save_text_artifact_and_record(
                workflow_id=workflow_id,
                agent_name=agent_name,
                subdir="rtl",
                filename="rtl_agent_compile.log",
                content=log_content,
            )
        except Exception as e:
            print(f"‚ö†Ô∏è Failed to upload RTL log artifact: {e}")

        # 2) Lint feedback
        lint_file = os.path.join(workflow_dir, "rtl_agent_lint_feedback.txt")
        try:
            with open(lint_file, "w") as lf:
                lf.write(lint_feedback or "")
            with open(lint_file, "r") as lf:
                lint_content = lf.read()
            save_text_artifact_and_record(
                workflow_id=workflow_id,
                agent_name=agent_name,
                subdir="rtl",
                filename="rtl_agent_lint_feedback.txt",
                content=lint_content,
            )
        except Exception as e:
            print(f"‚ö†Ô∏è Failed to upload RTL lint feedback artifact: {e}")

        # 3) Validation summary
        summary_file = os.path.join(workflow_dir, "rtl_agent_summary.txt")
        try:
            with open(summary_file, "w") as sf:
                sf.write(
                    f"{overall_status}\n\n"
                    f"Ports: {port_names}\n"
                    f"Clocks: {clocks_detected}\n"
                    f"Resets: {resets_detected}\n"
                    "Issues:\n"
                )
                for i in issues:
                    sf.write(f" - {i}\n")

            with open(summary_file, "r") as sf:
                summary_content = sf.read()
            save_text_artifact_and_record(
                workflow_id=workflow_id,
                agent_name=agent_name,
                subdir="rtl",
                filename="rtl_agent_summary.txt",
                content=summary_content,
            )
        except Exception as e:
            print(f"‚ö†Ô∏è Failed to upload RTL summary artifact: {e}")

        print("üß© RTL Agent artifacts uploaded successfully.")

    except Exception as e:
        print(f"‚ö†Ô∏è RTL Agent artifact upload failed: {e}")

    if artifact_list:
        for f in artifact_list:
            try:
                with open(f, "r") as vf:
                   v_content = vf.read()
                save_text_artifact_and_record(
                    workflow_id=workflow_id,
                    agent_name=agent_name,
                    subdir="rtl",
                    filename=os.path.basename(f),
                    content=v_content,
                )
            except Exception as e:
                print(f"‚ö†Ô∏è Failed to upload RTL module artifact {f}: {e}")
    

    return state


# --- Local Test Example ---
if __name__ == "__main__":
    state = {
        "artifact": "uart_tx.v",
        "spec_json": "uart_tx_spec.json",
        "workflow_id": "test_run_1"
    }
    result = run_agent(state)
    print(json.dumps(result, indent=2))

import os
import json
import glob
import shutil
import subprocess
from datetime import datetime

from utils.artifact_utils import save_text_artifact_and_record

AGENT_NAME = "Digital STA PrePlace Agent"

DEFAULT_PDK_VARIANT = os.getenv("CHIPLOOP_PDK_VARIANT", "sky130A")
DEFAULT_OPENLANE_IMAGE = os.getenv("CHIPLOOP_OPENLANE_IMAGE", "ghcr.io/efabless/openlane2:2.4.0.dev1")
DEFAULT_NUM_CORES = int(os.getenv("OPENLANE_NUM_CORES", "2"))


def _ensure_dir(p: str) -> None:
    os.makedirs(p, exist_ok=True)


def _read_json(path: str) -> dict:
    try:
        with open(path, "r", encoding="utf-8") as f:
            return json.load(f)
    except Exception:
        return {}


def _write_text(path: str, content: str) -> None:
    _ensure_dir(os.path.dirname(path))
    with open(path, "w", encoding="utf-8") as f:
        f.write(content)


def _run(cmd: list[str], cwd: str) -> tuple[int, str]:
    p = subprocess.Popen(cmd, cwd=cwd, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)
    out, _ = p.communicate()
    return p.returncode, out


def _latest_run_dir(stage_dir: str) -> str | None:
    runs_dir = os.path.join(stage_dir, "runs")
    if not os.path.isdir(runs_dir):
        return None
    dirs = [os.path.join(runs_dir, d) for d in os.listdir(runs_dir) if os.path.isdir(os.path.join(runs_dir, d))]
    if not dirs:
        return None
    dirs.sort(key=lambda p: os.path.getmtime(p))
    return dirs[-1]


def _copy_metrics(latest: str | None, stage_dir: str) -> str | None:
    if not latest:
        return None
    src = os.path.join(latest, "final", "metrics.json")
    dst = os.path.join(stage_dir, "metrics.json")
    if os.path.exists(src):
        shutil.copy2(src, dst)
        return dst
    return None


def _best_effort_top_module(spec: dict) -> str:
    tm = (
        spec.get("design_name")
        or spec.get("name")
        or (((spec.get("hierarchy") or {}).get("top_module") or {}).get("name") if isinstance(spec.get("hierarchy"), dict) else None)
        or spec.get("top_module")
        or "top"
    )
    return str(tm).strip() or "top"


def run_agent(state: dict) -> dict:
    print(f"\nüèÅ Running {AGENT_NAME}...")

    workflow_id = state.get("workflow_id", "default")
    workflow_dir = state.get("workflow_dir") or f"backend/workflows/{workflow_id}"

    stage_dir = os.path.join(workflow_dir, "digital", "sta_preplace")
    logs_dir = os.path.join(stage_dir, "logs")
    constraints_dir = os.path.join(stage_dir, "constraints")
    netlist_dir = os.path.join(stage_dir, "netlist")

    _ensure_dir(stage_dir)
    _ensure_dir(logs_dir)
    _ensure_dir(constraints_dir)
    _ensure_dir(netlist_dir)

    # ---- Inputs ----
    spec_dir = os.path.join(workflow_dir, "spec")
    spec_jsons = sorted(glob.glob(os.path.join(spec_dir, "*_spec.json")))
    spec = _read_json(spec_jsons[0]) if spec_jsons else {}
    top_module = _best_effort_top_module(spec)

    # Single source-of-truth SDC from Arch2RTL
    upstream_sdc = os.path.join(workflow_dir, "digital", "constraints", "top.sdc")
    if not os.path.exists(upstream_sdc):
        raise RuntimeError("Missing upstream SDC: digital/constraints/top.sdc (must be generated by Arch2RTL).")
    stage_sdc = os.path.join(constraints_dir, "top.sdc")
    shutil.copy2(upstream_sdc, stage_sdc)
    with open(stage_sdc, "r", encoding="utf-8") as f:
        sdc_text = f.read()

    # Prefer synthesized netlist if available (Arch2Synthesis output)
    synth_netlists = sorted(glob.glob(os.path.join(workflow_dir, "digital", "synth", "netlist", "*_synth.v")))
    if not synth_netlists:
        # fallback: any .v under digital/synth (best-effort)
        synth_netlists = sorted(glob.glob(os.path.join(workflow_dir, "digital", "synth", "**", "*.v"), recursive=True))
    if not synth_netlists:
        raise RuntimeError("No synthesized netlist found. Expected digital/synth/netlist/*_synth.v")

    # Copy netlist into stage dir (stable contract)
    stage_netlist = os.path.join(netlist_dir, os.path.basename(synth_netlists[0]))
    shutil.copy2(synth_netlists[0], stage_netlist)

    # OpenLane config for STA: use netlist + SDC
    config = {
        "DESIGN_NAME": top_module,
        "VERILOG_FILES": "netlist/*.v",
        "PNR_SDC_FILE": "constraints/top.sdc",
    }
    config_path = os.path.join(stage_dir, "config.json")
    _write_text(config_path, json.dumps(config, indent=2))

    # ---- Docker/run.sh ----
    pdk_variant = state.get("pdk_variant") or DEFAULT_PDK_VARIANT
    openlane_image = state.get("openlane_image") or DEFAULT_OPENLANE_IMAGE
    pdk_root_host = os.getenv("CHIPLOOP_PDK_ROOT_HOST") or "/root/chiploop-backend/backend/pdk"
    run_tag = f"sta_preplace_{workflow_id}"

    run_sh = f"""#!/usr/bin/env bash
set -euo pipefail

echo "== ChipLoop: {AGENT_NAME} =="
echo "PDK_VARIANT={pdk_variant}"
echo "OPENLANE_IMAGE={openlane_image}"
echo "WORKDIR=/work"

export OPENLANE_NUM_CORES={DEFAULT_NUM_CORES}

docker run --rm \\
  -v "{pdk_root_host}":/pdk \\
  -v "$(pwd)":/work \\
  -e PDK={pdk_variant} \\
  -e PDK_ROOT=/pdk \\
  {openlane_image} \\
  bash -lc 'set -e; echo "PDK listing:"; ls -la /pdk | head -n 50; cd /work && openlane --flow Classic --tag {run_tag} --to OpenROAD.STAPrePNR config.json'
"""
    run_sh_path = os.path.join(stage_dir, "run.sh")
    _write_text(run_sh_path, run_sh)
    os.chmod(run_sh_path, 0o755)

    rc, out = _run(["bash", "-lc", "./run.sh"], cwd=stage_dir)
    log_path = os.path.join(logs_dir, "openlane_sta_preplace.log")
    _write_text(log_path, out)

    latest = _latest_run_dir(stage_dir)
    metrics_path = _copy_metrics(latest, stage_dir)

    summary = {
        "workflow_id": workflow_id,
        "agent": AGENT_NAME,
        "status": "ok" if rc == 0 else "failed",
        "return_code": rc,
        "top_module": top_module,
        "outputs": {
            "sdc": "digital/sta_preplace/constraints/top.sdc",
            "netlist": f"digital/sta_preplace/netlist/{os.path.basename(stage_netlist)}",
            "metrics_json": "digital/sta_preplace/metrics.json" if metrics_path else None,
            "log": "digital/sta_preplace/logs/openlane_sta_preplace.log",
            "openlane_run_dir": latest,
        },
    }

    _write_text(os.path.join(stage_dir, "sta_summary.json"), json.dumps(summary, indent=2))
    _write_text(os.path.join(stage_dir, "sta_summary.md"), f"# STA PrePlace\n\n- status: `{summary['status']}` (rc={rc})\n")

    # ---- Upload text artifacts ----
    try:
        save_text_artifact_and_record(workflow_id, AGENT_NAME, "digital", "sta_preplace/config.json", json.dumps(config, indent=2))
        save_text_artifact_and_record(workflow_id, AGENT_NAME, "digital", "sta_preplace/constraints/top.sdc", sdc_text)
        save_text_artifact_and_record(workflow_id, AGENT_NAME, "digital", "sta_preplace/run.sh", run_sh)
        save_text_artifact_and_record(workflow_id, AGENT_NAME, "digital", "sta_preplace/logs/openlane_sta_preplace.log", out)
        save_text_artifact_and_record(workflow_id, AGENT_NAME, "digital", "sta_preplace/sta_summary.json", json.dumps(summary, indent=2))
        if metrics_path and os.path.exists(metrics_path):
            with open(metrics_path, "r", encoding="utf-8") as f:
                save_text_artifact_and_record(workflow_id, AGENT_NAME, "digital", "sta_preplace/metrics.json", f.read())
    except Exception as e:
        print(f"‚ö†Ô∏è {AGENT_NAME} upload failed: {e}")

    state.setdefault("digital", {})["sta_preplace"] = {
        "status": summary["status"],
        "stage_dir": stage_dir,
        "metrics_json": metrics_path,
    }
    return state